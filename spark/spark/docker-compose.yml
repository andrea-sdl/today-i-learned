version: '2.1'

services:
    spark-master:
      image: bde2020/spark-master:2.4.4-hadoop2.7
      container_name: spark-master
      ports:
        - "6060:6060"
        - "7077:7077"
      networks: 
        spark-network:
          ipv4_address: 10.5.0.2
      environment:
        - INIT_DAEMON_STEP=setup_spark
        - "constraint:node==<yourmasternode>"
      volumes:
        - ./spark-apps:/opt/spark-apps
    spark-worker-1:
      image: bde2020/spark-worker:2.4.4-hadoop2.7
      container_name: spark-worker-1
      depends_on:
        - spark-master
      ports:
        - "6061:6061"
      networks: 
        spark-network:
          ipv4_address: 10.5.0.3
      environment:
        - "SPARK_MASTER=spark://spark-master:7077"
        - "constraint:node==<yourworkernode>"
    spark-worker-2:
      image: bde2020/spark-worker:2.4.4-hadoop2.7
      container_name: spark-worker-2
      depends_on:
        - spark-master
      ports:
        - "6062:6062"
      networks: 
        spark-network:
          ipv4_address: 10.5.0.4
      environment:
        - "SPARK_MASTER=spark://spark-master:7077"
        - "constraint:node==<yourworkernode>"  
networks:
  spark-network:
    driver: bridge
    ipam:
     driver: default
     config:
       - subnet: 10.5.0.0/16